{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13ad028b-72b7-43ed-aa78-96fd4e518040",
   "metadata": {
    "id": "13ad028b-72b7-43ed-aa78-96fd4e518040"
   },
   "source": [
    "# Assignment: Data Wrangling\n",
    "### `! git clone https://github.com/ds3001f25/wrangling_assignment.git`\n",
    "### Do Q1 and Q2\n",
    "### Reading material: `tidy_data.pdf`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da879ea7-8aac-48a3-b6c2-daea56d2e072",
   "metadata": {
    "id": "da879ea7-8aac-48a3-b6c2-daea56d2e072"
   },
   "source": [
    "**Q1.** This question provides some practice cleaning variables which have common problems.\n",
    "1. Numeric variable: For `./data/airbnb_hw.csv`, clean the `Price` variable as well as you can, and explain the choices you make. How many missing values do you end up with? (Hint: What happens to the formatting when a price goes over 999 dollars, say from 675 to 1,112?)\n",
    "\n",
    "When cleaning the Price variable, the first choice I made was to remove any \"$\" and \",\"s that might be in the column due to seeing that the column type intially was object. From there, I made sure to coerce the column into a more appropriate type like float. With all this done, I see there's no missing values, as all the values were able to be properly coerced.\n",
    "\n",
    "2. Categorical variable: For the Minnesota police use of for data, `./data/mn_police_use_of_force.csv`, clean the `subject_injury` variable, handling the NA's; this gives a value `Yes` when a person was injured by police, and `No` when no injury occurred. What proportion of the values are missing? Is this a concern? Cross-tabulate your cleaned `subject_injury` variable with the `force_type` variable. Are there any patterns regarding when the data are missing? \n",
    "\n",
    "There are 9848 entries missing out of 11294. This is a concern, as this means that 87% of the entries are missing. When cross-tabulating, we see that the majority of the missing entries when the force type was \"bodily force\".\n",
    "\n",
    "3. Dummy variable: For the pretrial data covered in the lecture `./data/justice_data.parquet`, clean the `WhetherDefendantWasReleasedPretrial` variable as well as you can, and, in particular, replace missing values with `np.nan`.\n",
    "\n",
    "4. Missing values, not at random: For the pretrial data covered in the lecture, clean the `ImposedSentenceAllChargeInContactEvent` variable as well as you can, and explain the choices you make. (Hint: Look at the `SentenceTypeAllChargesAtConvictionInContactEvent` variable.)\n",
    "\n",
    "After seeing most of most of the entries were \" \", I replaced those with NAs to better reflect the data. From there, by cross-tabulating with sentence type, I saw all the NAs were associated with sentence types 4 and 9, which might be for cases where there's no sentence being handed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d412a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import pandas as pd\n",
    "\n",
    "airbnb = pd.read_csv('./data/airbnb_hw.csv',low_memory=False)\n",
    "\n",
    "var = 'Price' \n",
    "print('Before coercion: \\n', airbnb[var].describe(),'\\n')\n",
    "airbnb[var].hist(bins=50) \n",
    "\n",
    "airbnb[\"Price\"] = airbnb[\"Price\"].str.replace(r\"[\\$,]\", \"\", regex=True).astype(float)\n",
    "\n",
    "airbnb['Price'] = pd.to_numeric(airbnb['Price'], errors='coerce')\n",
    "\n",
    "airbnb['price_nan'] = airbnb['Price'].isnull() \n",
    "\n",
    "print('After coercion: \\n', airbnb['Price'].describe(),'\\n') \n",
    "airbnb['Price'].hist(bins = 50) \n",
    "print('Total Missings: \\n', sum(airbnb['price_nan']),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a0ef3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "police = pd.read_csv('./data/mn_police_use_of_force.csv',low_memory=False)\n",
    "\n",
    "var = \"subject_injury\"\n",
    "\n",
    "police[\"injury_na\"] = police[var].isnull()\n",
    "\n",
    "print(police[\"injury_na\"].value_counts(), '\\n')\n",
    "\n",
    "print(police[\"subject_injury\"].value_counts(), '\\n')\n",
    "\n",
    "print(police[var].unique(), '\\n')\n",
    "\n",
    "#police[var] = police[var].replace(nan ,np.nan)\n",
    "#police[var].value_counts()\n",
    "\n",
    "pd.crosstab(police[\"injury_na\"], police[\"force_type\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dce53d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://www.vcsc.virginia.gov/pretrialdataproject/October%202017%20Cohort_Virginia%20Pretrial%20Data%20Project_Deidentified%20FINAL%20Update_10272021.csv'\n",
    "justice = pd.read_csv(url,low_memory=False)\n",
    "\n",
    "print(justice[\"WhetherDefendantWasReleasedPretrial\"].unique(), '\\n')\n",
    "\n",
    "justice[\"WhetherDefendantWasReleasedPretrial\"] = justice[\"WhetherDefendantWasReleasedPretrial\"].replace(9, np.nan)\n",
    "\n",
    "print(justice[\"WhetherDefendantWasReleasedPretrial\"].value_counts(), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86311727",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(justice['ImposedSentenceAllChargeInContactEvent'].value_counts(dropna=False).head(20))\n",
    "\n",
    "justice['ImposedSentenceAllChargeInContactEvent'] = justice['ImposedSentenceAllChargeInContactEvent'].replace(\" \", np.nan)\n",
    "\n",
    "pd.crosstab(justice['SentenceTypeAllChargesAtConvictionInContactEvent'],justice['ImposedSentenceAllChargeInContactEvent'].isna(), margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8944ee12",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(justice['ImposedSentenceAllChargeInContactEvent'].value_counts(dropna=False).head(20))\n",
    "\n",
    "justice['ImposedSentenceAllChargeInContactEvent'] = justice['ImposedSentenceAllChargeInContactEvent'].replace(\" \", np.nan)\n",
    "\n",
    "pd.crosstab(justice['SentenceTypeAllChargesAtConvictionInContactEvent'],justice['ImposedSentenceAllChargeInContactEvent'].isna(), margins=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a60a44e",
   "metadata": {},
   "source": [
    "**Q2.** Go to https://sharkattackfile.net/ and download their dataset on shark attacks (Hint: `GSAF5.xls`).\n",
    "\n",
    "1. Open the shark attack file using Pandas. It is probably not a csv file, so `read_csv` won't work.\n",
    "2. Drop any columns that do not contain data.\n",
    "3. Clean the year variable. Describe the range of values you see. Filter the rows to focus on attacks since 1940. Are attacks increasing, decreasing, or remaining constant over time?\n",
    "\n",
    "The original range of years is from 1900 - 2026. Since the 1940s, attacks have constantly fluctuated over time, but are around the same levels they were at at 1940.\n",
    "\n",
    "4. Clean the Age variable and make a histogram of the ages of the victims.\n",
    "5. What proportion of victims are male?\n",
    "\n",
    "There were 4333 men out of 5053 victims.\n",
    "\n",
    "6. Clean the `Type` variable so it only takes three values: Provoked and Unprovoked and Unknown. What proportion of attacks are unprovoked?\n",
    "\n",
    "The proportion of unprokved attacks are 74.4%.\n",
    "\n",
    "7. Clean the `Fatal Y/N` variable so it only takes three values: Y, N, and Unknown.\n",
    "8. Are sharks more likely to launch unprovoked attacks on men or women? Is the attack more or less likely to be fatal when the attack is provoked or unprovoked? Is it more or less likely to be fatal when the victim is male or female? How do you feel about sharks?\n",
    "\n",
    "Sharks are far more likely to launch unprovoked attacks on men than women, attacks are much more likely to be fatal when unprovoked, and fatality rates are slightly higher for men than for women.\n",
    "\n",
    "9. What proportion of attacks appear to be by white sharks? (Hint: `str.split()` makes a vector of text values into a list of lists, split by spaces.)\n",
    "\n",
    "About 12.87% of attacks are by white sharks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f03830",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import pandas as pd  \n",
    "\n",
    "shark_url = 'https://sharkattackfile.net/spreadsheets/GSAF5.xls'\n",
    "shark = pd.read_excel(shark_url)\n",
    "\n",
    "print(shark.shape, '\\n') \n",
    "\n",
    "shark = shark.dropna(axis=1, how='all')\n",
    "print(shark.shape, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b568e041",
   "metadata": {},
   "outputs": [],
   "source": [
    "shark.loc[shark['Year'] < 1800, 'Year'] = np.nan\n",
    "\n",
    "print(shark[\"Year\"].describe(), '\\n')\n",
    "\n",
    "shark = shark[shark['Year'] >= 1940]  \n",
    "shark['Year'].hist(bins=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e21b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "shark['Age'] = pd.to_numeric(shark['Age'], errors='coerce')\n",
    "shark['Age'].hist(bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51ed84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(shark[\"Sex\"].value_counts(dropna=False))\n",
    "\n",
    "shark[\"Sex\"] = shark[\"Sex\"].str.strip().str.upper()\n",
    "\n",
    "shark.loc[~shark[\"Sex\"].isin(['M', 'F']), \"Sex\"] = np.nan\n",
    "\n",
    "print(shark[\"Sex\"].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd08388",
   "metadata": {},
   "outputs": [],
   "source": [
    "shark['Type'] = shark['Type'].str.strip().str.capitalize()\n",
    "shark['Type'] = shark['Type'].where(shark['Type'].isin(['Unprovoked', 'Provoked']), 'Unknown')\n",
    "print(shark['Type'].value_counts(normalize=True), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c679f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "shark['Fatal Y/N'] = shark['Fatal Y/N'].str.strip().str.upper()\n",
    "shark['Fatal Y/N'] = shark['Fatal Y/N'].where(shark['Fatal Y/N'].isin(['Y', 'N']), 'Unknown')\n",
    "print(shark['Fatal Y/N'].value_counts(normalize=True), '\\n')\n",
    "\n",
    "print(pd.crosstab(shark['Sex'], shark['Type'], normalize='columns'), '\\n')\n",
    "\n",
    "print(pd.crosstab(shark['Type'], shark['Fatal Y/N'], normalize='index'), '\\n')\n",
    "\n",
    "print(pd.crosstab(shark['Sex'], shark['Fatal Y/N'], normalize='index'), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5374f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "shark[\"Species \"] = shark[\"Species \"].astype(str).str.lower()\n",
    "\n",
    "shark['white_shark'] = shark[\"Species \"].str.contains('white', na=False)\n",
    "print(shark['white_shark'].mean(), '\\n')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
